{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "65978fb7-37a7-4ec5-b12b-9a4e12fe7a4b",
    "_execution_state": "idle",
    "_uuid": "588e57dbef35d1569e10c7ef63fa8a4bdebe7250"
   },
   "source": [
    "Training a perceptron neural net from scratch using the sepal length & width, petal length & width as data inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "6d32d571-c823-41b0-b04f-7e804936cabd",
    "_execution_state": "idle",
    "_uuid": "9d26bbb1099bcc75c46be854bdd0ae6a22fe9cc0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import exp, array, random, dot, genfromtxt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "566a4b01-677d-410e-b41a-a45fddd504ab",
    "_execution_state": "idle",
    "_uuid": "ffe7fb4547d5c15e0a445288a6089d1489cffbc4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuronLayer():\n",
    "    def __init__(self, number_of_neurons, number_of_inputs_per_neuron):\n",
    "        self.synaptic_weights = 2 * random.random((number_of_inputs_per_neuron, number_of_neurons)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "1bdfa64e-0728-4379-8c7b-4595cc060157",
    "_execution_state": "idle",
    "_uuid": "1e5f024a86d50e3cb2a0e6aec25940f02ee0d023",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, layer1):\n",
    "        # Seed the random number generator, so it generates the same numbers\n",
    "        # every time the program runs.\n",
    "        self.layer1 = layer1\n",
    "        \n",
    "    # The Sigmoid function, which describes an S shaped curve.\n",
    "    # We pass the weighted sum of the inputs through this function to\n",
    "    # normalise them between 0 and 1.\n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + exp(-x))\n",
    "\n",
    "    # The derivative of the Sigmoid function.\n",
    "    # This is the gradient of the Sigmoid curve.\n",
    "    # It indicates how confident we are about the existing weight.\n",
    "    def __sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    # We train the neural network through a process of trial and error.\n",
    "    # Adjusting the synaptic weights each time.\n",
    "    def train(self, training_set_inputs, training_set_outputs, number_of_training_iterations):\n",
    "        for iteration in xrange(number_of_training_iterations):\n",
    "            # Pass the training set through our neural network (a single neuron).\n",
    "            output = self.think(training_set_inputs)\n",
    "\n",
    "            # Calculate the error (The difference between the desired output\n",
    "            # and the predicted output).\n",
    "            error = training_set_outputs - output\n",
    "\n",
    "            # Multiply the error by the input and again by the gradient of the Sigmoid curve.\n",
    "            # This means less confident weights are adjusted more.\n",
    "            # This means inputs, which are zero, do not cause changes to the weights.\n",
    "            adjustment = dot(training_set_inputs.T, error * self.__sigmoid_derivative(output))\n",
    "\n",
    "            # Adjust the weights.\n",
    "            self.layer1.synaptic_weights += adjustment*0.01\n",
    "\n",
    "    # The neural network thinks.\n",
    "    def think(self, inputs):\n",
    "        # Pass inputs through our neural network (our single neuron).\n",
    "        return self.__sigmoid(dot(inputs, self.layer1.synaptic_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "3f2dcaf8-4c68-48cb-b593-67336ebdfa78",
    "_execution_state": "idle",
    "_uuid": "6a745824b1290576ef102733c9ba14a5b8fbb34a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ nan]\n",
      "[ 0.00038267]\n",
      "[ 0.00185387]\n",
      "[ 0.00082315]\n",
      "[ 0.00292791]\n",
      "[ 0.00031901]\n",
      "[ 0.00056492]\n",
      "[ 0.00101472]\n",
      "[ 0.00087028]\n",
      "[ 0.00393867]\n",
      "[ 0.00176556]\n",
      "[ 0.0002583]\n",
      "[ 0.00164935]\n",
      "[ 0.00163712]\n",
      "[ 0.00068746]\n",
      "[  1.99333562e-05]\n",
      "[  4.31415223e-05]\n",
      "[  9.38397958e-05]\n",
      "[ 0.00047687]\n",
      "[ 0.00044919]\n",
      "[ 0.00032487]\n",
      "[ 0.00145619]\n",
      "[ 0.00053432]\n",
      "[  7.76590504e-05]\n",
      "[ 0.00493949]\n",
      "[ 0.00631148]\n",
      "[ 0.00412545]\n",
      "[ 0.00211494]\n",
      "[ 0.00054473]\n",
      "[ 0.00045903]\n",
      "[ 0.00315731]\n",
      "[ 0.00378523]\n",
      "[ 0.0009221]\n",
      "[  8.26701347e-05]\n",
      "[  3.74023308e-05]\n",
      "[ 0.00176556]\n",
      "[ 0.00039459]\n",
      "[ 0.00016668]\n",
      "[ 0.00176556]\n",
      "[ 0.00190859]\n",
      "[ 0.00079099]\n",
      "[ 0.00033499]\n",
      "[ 0.01489737]\n",
      "[ 0.00109629]\n",
      "[ 0.0024877]\n",
      "[ 0.00243338]\n",
      "[ 0.0025405]\n",
      "[ 0.00040833]\n",
      "[ 0.00141806]\n",
      "[ 0.00028421]\n",
      "[ 0.00073339]\n",
      "Other\n",
      "[ 0.99981662]\n",
      "[ 0.99979653]\n",
      "[ 0.99995871]\n",
      "[ 0.99989632]\n",
      "[ 0.99995292]\n",
      "[ 0.99994668]\n",
      "[ 0.99992018]\n",
      "[ 0.99655491]\n",
      "[ 0.99989379]\n",
      "[ 0.99970305]\n",
      "[ 0.99948971]\n",
      "[ 0.99972166]\n",
      "[ 0.99975479]\n",
      "[ 0.99996627]\n",
      "[ 0.9963782]\n",
      "[ 0.99959915]\n",
      "[ 0.99994564]\n",
      "[ 0.99948207]\n",
      "[ 0.99998953]\n",
      "[ 0.99951651]\n",
      "[ 0.99998305]\n",
      "[ 0.99926309]\n",
      "[ 0.9999956]\n",
      "[ 0.99996031]\n",
      "[ 0.99966281]\n",
      "[ 0.99972398]\n",
      "[ 0.99996815]\n",
      "[ 0.99998938]\n",
      "[ 0.99993964]\n",
      "[ 0.99475404]\n",
      "[ 0.99947853]\n",
      "[ 0.99898239]\n",
      "[ 0.99918189]\n",
      "[ 0.99999812]\n",
      "[ 0.9999551]\n",
      "[ 0.99980594]\n",
      "[ 0.99991631]\n",
      "[ 0.99996301]\n",
      "[ 0.99949173]\n",
      "[ 0.99981936]\n",
      "[ 0.99995065]\n",
      "[ 0.99993025]\n",
      "[ 0.9996042]\n",
      "[ 0.99712657]\n",
      "[ 0.99985888]\n",
      "[ 0.99955505]\n",
      "[ 0.99972948]\n",
      "[ 0.99972148]\n",
      "[ 0.98324249]\n",
      "[ 0.99967896]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    random.seed(1)\n",
    "\n",
    "    # 1 neurons, 4 inputs    \n",
    "    layer1 = NeuronLayer(1, 4)\n",
    "\n",
    "    neural_network = NeuralNetwork(layer1)\n",
    "\n",
    "    dataset = genfromtxt('IRIS.csv', delimiter=',')\n",
    "    \n",
    "    training_set_inputs = array(dataset[1:, :-1])\n",
    "    training_set_outputs = np.reshape(array(dataset[1:, -1]), (-1, 1))\n",
    "    \n",
    "    neural_network.train(training_set_inputs, training_set_outputs, 100000)\n",
    "\n",
    "\n",
    "    for i in range(51):\n",
    "        output4 = neural_network.think(array(dataset[i,:-1]))    \n",
    "        print(output4)\n",
    "        \n",
    "    print(\"Other\")\n",
    "    for i in range(50):\n",
    "        output4 = neural_network.think(array(dataset[i+51,:-1]))    \n",
    "        print(output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
